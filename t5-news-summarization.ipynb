{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nT5 Fine-tuning for Text Summarization on CNN/DailyMail Dataset\n\"\"\"\n\n# Install required packages\n!pip install transformers datasets rouge-score nltk accelerate -q\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW \nfrom transformers import (\n    T5Tokenizer, \n    T5ForConditionalGeneration,\n    get_linear_schedule_with_warmup\n)\nfrom datasets import load_dataset\nfrom rouge_score import rouge_scorer\nimport nltk\nfrom tqdm.auto import tqdm\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Download NLTK data for sentence tokenization\nnltk.download('punkt', quiet=True)\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n\n# ============================================\n# 1. CONFIGURATION\n# ============================================\n\nclass Config:\n    # Model\n    MODEL_NAME = \"t5-small\"  \n    MAX_SOURCE_LENGTH = 512\n    MAX_TARGET_LENGTH = 128\n    \n    # Training\n    BATCH_SIZE = 4  \n    GRADIENT_ACCUMULATION_STEPS = 4  # Effective batch size = 4 * 4 = 16\n    LEARNING_RATE = 3e-4\n    NUM_EPOCHS = 3\n    WARMUP_STEPS = 500\n    MAX_GRAD_NORM = 1.0\n    \n    # Data\n    TRAIN_SIZE = 10000  \n    VAL_SIZE = 1000\n    \n    # Paths\n    OUTPUT_DIR = \"/kaggle/working/t5_summarization\"\n    CHECKPOINT_DIR = f\"{OUTPUT_DIR}/checkpoints\"\n    \n    # Mixed Precision\n    USE_FP16 = True\n\nconfig = Config()\nos.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n\n# ============================================\n# 2. DATASET PREPARATION\n# ============================================\n\nclass SummarizationDataset(Dataset):\n    def __init__(self, articles, summaries, tokenizer, max_source_len, max_target_len):\n        self.articles = articles\n        self.summaries = summaries\n        self.tokenizer = tokenizer\n        self.max_source_len = max_source_len\n        self.max_target_len = max_target_len\n    \n    def __len__(self):\n        return len(self.articles)\n    \n    def __getitem__(self, idx):\n        article = str(self.articles[idx])\n        summary = str(self.summaries[idx])\n        \n        # T5 requires task prefix\n        article = \"summarize: \" + article\n        \n        # Tokenize inputs\n        source = self.tokenizer(\n            article,\n            max_length=self.max_source_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        # Tokenize targets\n        target = self.tokenizer(\n            summary,\n            max_length=self.max_target_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        source_ids = source['input_ids'].squeeze()\n        source_mask = source['attention_mask'].squeeze()\n        target_ids = target['input_ids'].squeeze()\n        \n        # Replace padding token id with -100 for loss calculation\n        target_ids[target_ids == self.tokenizer.pad_token_id] = -100\n        \n        return {\n            'input_ids': source_ids,\n            'attention_mask': source_mask,\n            'labels': target_ids\n        }\n\ndef load_and_prepare_data(tokenizer):\n    \"\"\"Load CNN/DailyMail dataset from Hugging Face or Kaggle\"\"\"\n    \n    print(\"Loading dataset...\")\n    \n    # Option 1: Load from Hugging Face (recommended)\n    try:\n        dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n        \n        # Extract train and validation splits\n        if config.TRAIN_SIZE:\n            train_data = dataset['train'].select(range(config.TRAIN_SIZE))\n        else:\n            train_data = dataset['train']\n        \n        if config.VAL_SIZE:\n            val_data = dataset['validation'].select(range(config.VAL_SIZE))\n        else:\n            val_data = dataset['validation']\n        \n        train_articles = train_data['article']\n        train_summaries = train_data['highlights']\n        val_articles = val_data['article']\n        val_summaries = val_data['highlights']\n        \n        print(\"✓ Dataset loaded from Hugging Face\")\n    \n    except Exception as e:\n        print(f\"Could not load from Hugging Face: {e}\")\n        print(\"Loading from Kaggle dataset...\")\n        \n        # Option 2: Load from Kaggle CSV\n        # Adjust path based on your Kaggle setup\n        try:\n            df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')\n            \n            # Split into train and validation\n            train_size = config.TRAIN_SIZE if config.TRAIN_SIZE else int(len(df) * 0.9)\n            val_size = config.VAL_SIZE if config.VAL_SIZE else int(len(df) * 0.1)\n            \n            train_df = df.iloc[:train_size]\n            val_df = df.iloc[train_size:train_size + val_size]\n            \n            train_articles = train_df['article'].tolist()\n            train_summaries = train_df['highlights'].tolist()\n            val_articles = val_df['article'].tolist()\n            val_summaries = val_df['highlights'].tolist()\n            \n            print(\"✓ Dataset loaded from Kaggle\")\n        except Exception as e2:\n            print(f\"Error loading from Kaggle: {e2}\")\n            raise RuntimeError(\"Could not load dataset from either Hugging Face or Kaggle\")\n    \n    print(f\"Train size: {len(train_articles)}\")\n    print(f\"Validation size: {len(val_articles)}\")\n    \n    # Create datasets\n    train_dataset = SummarizationDataset(\n        train_articles, train_summaries, tokenizer,\n        config.MAX_SOURCE_LENGTH, config.MAX_TARGET_LENGTH\n    )\n    \n    val_dataset = SummarizationDataset(\n        val_articles, val_summaries, tokenizer,\n        config.MAX_SOURCE_LENGTH, config.MAX_TARGET_LENGTH\n    )\n    \n    return train_dataset, val_dataset, val_articles, val_summaries\n\n# ============================================\n# 3. EVALUATION METRICS\n# ============================================\n\ndef compute_rouge_scores(predictions, references):\n    \"\"\"Compute ROUGE scores\"\"\"\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    \n    rouge1_scores = []\n    rouge2_scores = []\n    rougeL_scores = []\n    \n    for pred, ref in zip(predictions, references):\n        scores = scorer.score(ref, pred)\n        rouge1_scores.append(scores['rouge1'].fmeasure)\n        rouge2_scores.append(scores['rouge2'].fmeasure)\n        rougeL_scores.append(scores['rougeL'].fmeasure)\n    \n    return {\n        'rouge1': np.mean(rouge1_scores),\n        'rouge2': np.mean(rouge2_scores),\n        'rougeL': np.mean(rougeL_scores)\n    }\n\n# ============================================\n# 4. TRAINING LOOP\n# ============================================\n\ndef train_epoch(model, dataloader, optimizer, scheduler, scaler=None):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    total_loss = 0\n    progress_bar = tqdm(dataloader, desc=\"Training\")\n    \n    optimizer.zero_grad()\n    \n    for step, batch in enumerate(progress_bar):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        # Mixed precision training\n        if config.USE_FP16 and scaler and torch.cuda.is_available():\n            with torch.cuda.amp.autocast():\n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels\n                )\n                loss = outputs.loss / config.GRADIENT_ACCUMULATION_STEPS\n            \n            scaler.scale(loss).backward()\n            \n            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n                scaler.step(optimizer)\n                scaler.update()\n                scheduler.step()\n                optimizer.zero_grad()\n        else:\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            loss = outputs.loss / config.GRADIENT_ACCUMULATION_STEPS\n            loss.backward()\n            \n            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n                optimizer.step()\n                scheduler.step()\n                optimizer.zero_grad()\n        \n        total_loss += loss.item() * config.GRADIENT_ACCUMULATION_STEPS\n        progress_bar.set_postfix({'loss': f'{loss.item() * config.GRADIENT_ACCUMULATION_STEPS:.4f}'})\n    \n    return total_loss / len(dataloader)\n\ndef validate(model, dataloader, tokenizer):\n    \"\"\"Validate the model\"\"\"\n    model.eval()\n    total_loss = 0\n    predictions = []\n    \n    progress_bar = tqdm(dataloader, desc=\"Validation\")\n    \n    with torch.no_grad():\n        for batch in progress_bar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            \n            total_loss += outputs.loss.item()\n            \n            # Generate summaries\n            generated_ids = model.generate(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                max_length=config.MAX_TARGET_LENGTH,\n                num_beams=4,\n                length_penalty=2.0,\n                early_stopping=True\n            )\n            \n            decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n            predictions.extend(decoded_preds)\n            \n            progress_bar.set_postfix({'loss': f'{outputs.loss.item():.4f}'})\n    \n    avg_loss = total_loss / len(dataloader)\n    return avg_loss, predictions\n\n# ============================================\n# 5. MAIN TRAINING FUNCTION\n# ============================================\n\ndef train_model():\n    \"\"\"Main training function\"\"\"\n    print(\"=\" * 50)\n    print(\"T5 FINE-TUNING FOR TEXT SUMMARIZATION\")\n    print(\"=\" * 50)\n    \n    # Initialize tokenizer and model\n    print(f\"\\nLoading {config.MODEL_NAME}...\")\n    tokenizer = T5Tokenizer.from_pretrained(config.MODEL_NAME, legacy=False)\n    model = T5ForConditionalGeneration.from_pretrained(config.MODEL_NAME)\n    model.to(device)\n    \n    print(f\"✓ Model loaded: {sum(p.numel() for p in model.parameters()):,} parameters\")\n    \n    # Load and prepare data\n    train_dataset, val_dataset, val_articles, val_summaries = load_and_prepare_data(tokenizer)\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config.BATCH_SIZE,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config.BATCH_SIZE,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # Setup optimizer and scheduler\n    optimizer = AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=0.01)\n    \n    total_steps = len(train_loader) * config.NUM_EPOCHS // config.GRADIENT_ACCUMULATION_STEPS\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=config.WARMUP_STEPS,\n        num_training_steps=total_steps\n    )\n    \n    print(f\"✓ Total training steps: {total_steps}\")\n    \n    # Mixed precision scaler\n    scaler = torch.cuda.amp.GradScaler() if (config.USE_FP16 and torch.cuda.is_available()) else None\n    \n    # Training history\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'rouge1': [],\n        'rouge2': [],\n        'rougeL': []\n    }\n    \n    best_rougeL = 0\n    \n    # Training loop\n    for epoch in range(config.NUM_EPOCHS):\n        print(f\"\\n{'=' * 50}\")\n        print(f\"Epoch {epoch + 1}/{config.NUM_EPOCHS}\")\n        print(f\"{'=' * 50}\")\n        \n        # Train\n        train_loss = train_epoch(model, train_loader, optimizer, scheduler, scaler)\n        print(f\"\\nTrain Loss: {train_loss:.4f}\")\n        \n        # Validate\n        val_loss, predictions = validate(model, val_loader, tokenizer)\n        print(f\"Validation Loss: {val_loss:.4f}\")\n        \n        # Compute ROUGE scores\n        rouge_scores = compute_rouge_scores(predictions, val_summaries[:len(predictions)])\n        print(f\"\\nROUGE Scores:\")\n        print(f\"  ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n        print(f\"  ROUGE-2: {rouge_scores['rouge2']:.4f}\")\n        print(f\"  ROUGE-L: {rouge_scores['rougeL']:.4f}\")\n        \n        # Save history\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['rouge1'].append(rouge_scores['rouge1'])\n        history['rouge2'].append(rouge_scores['rouge2'])\n        history['rougeL'].append(rouge_scores['rougeL'])\n        \n        # Save best model\n        if rouge_scores['rougeL'] > best_rougeL:\n            best_rougeL = rouge_scores['rougeL']\n            print(f\"\\n✓ New best model! Saving checkpoint...\")\n            model.save_pretrained(f\"{config.CHECKPOINT_DIR}/best_model\")\n            tokenizer.save_pretrained(f\"{config.CHECKPOINT_DIR}/best_model\")\n        \n        # Save checkpoint\n        checkpoint_path = f\"{config.CHECKPOINT_DIR}/epoch_{epoch + 1}\"\n        model.save_pretrained(checkpoint_path)\n        tokenizer.save_pretrained(checkpoint_path)\n        print(f\"✓ Checkpoint saved to {checkpoint_path}\")\n    \n    # Save training history\n    with open(f\"{config.OUTPUT_DIR}/training_history.json\", 'w') as f:\n        json.dump(history, f, indent=2)\n    \n    print(\"\\n\" + \"=\" * 50)\n    print(\"TRAINING COMPLETED!\")\n    print(\"=\" * 50)\n    print(f\"Best ROUGE-L Score: {best_rougeL:.4f}\")\n    \n    return model, tokenizer, history\n\n# ============================================\n# 6. EXAMPLE GENERATION & EVALUATION\n# ============================================\n\ndef generate_examples(model, tokenizer, articles, references, num_examples=5):\n    \"\"\"Generate example summaries\"\"\"\n    model.eval()\n    \n    examples = []\n    \n    for i in range(min(num_examples, len(articles))):\n        article = \"summarize: \" + str(articles[i])\n        \n        inputs = tokenizer(\n            article,\n            max_length=config.MAX_SOURCE_LENGTH,\n            truncation=True,\n            return_tensors='pt'\n        ).to(device)\n        \n        with torch.no_grad():\n            summary_ids = model.generate(\n                inputs['input_ids'],\n                max_length=config.MAX_TARGET_LENGTH,\n                num_beams=4,\n                length_penalty=2.0,\n                early_stopping=True\n            )\n        \n        generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n        \n        examples.append({\n            'article': str(articles[i])[:500] + \"...\",  # Truncate for display\n            'reference': str(references[i]),\n            'generated': generated_summary\n        })\n    \n    return examples\n\n# ============================================\n# 7. RUN TRAINING\n# ============================================\n\nif __name__ == \"__main__\":\n    # Train the model\n    model, tokenizer, history = train_model()\n    \n    # Load validation data for examples\n    print(\"\\nGenerating example summaries...\")\n    try:\n        dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n        val_data = dataset['validation'].select(range(10))\n        \n        examples = generate_examples(\n            model, \n            tokenizer,\n            val_data['article'],\n            val_data['highlights'],\n            num_examples=5\n        )\n    except:\n        print(\"Could not load validation data for examples\")\n        examples = []\n    \n    # Display examples\n    if examples:\n        print(\"\\n\" + \"=\" * 50)\n        print(\"EXAMPLE SUMMARIES\")\n        print(\"=\" * 50)\n        \n        for i, ex in enumerate(examples, 1):\n            print(f\"\\n--- Example {i} ---\")\n            print(f\"\\nArticle (truncated):\\n{ex['article']}\")\n            print(f\"\\nReference Summary:\\n{ex['reference']}\")\n            print(f\"\\nGenerated Summary:\\n{ex['generated']}\")\n            print(\"\\n\" + \"-\" * 50)\n    \n    print(\"\\n✓ All done! Model saved to:\", config.CHECKPOINT_DIR)\n    print(f\"✓ Training history saved to: {config.OUTPUT_DIR}/training_history.json\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:44:26.519266Z","iopub.execute_input":"2025-10-30T16:44:26.519918Z","iopub.status.idle":"2025-10-30T17:14:23.967928Z","shell.execute_reply.started":"2025-10-30T16:44:26.519889Z","shell.execute_reply":"2025-10-30T17:14:23.966995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n!pip uninstall transformers -y\n!pip install transformers==4.36.0 torch==2.1.0 -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nfolder_path = \"/kaggle/working/t5_summarization/checkpoints\"\nzip_path = \"/kaggle/working/t5_checkpoints.zip\"\n\nshutil.make_archive(zip_path.replace('.zip', ''), 'zip', folder_path)\n\nprint(\"✅ Zipped successfully! Now check the right panel under 'Output > Files' for:\")\nprint(zip_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T17:16:20.106269Z","iopub.execute_input":"2025-10-30T17:16:20.106609Z","iopub.status.idle":"2025-10-30T17:17:07.773776Z","shell.execute_reply.started":"2025-10-30T17:16:20.106573Z","shell.execute_reply":"2025-10-30T17:17:07.773088Z"}},"outputs":[],"execution_count":null}]}